{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupied-crazy",
   "metadata": {},
   "source": [
    "<h1>Reading ERA5 data with xarray & Dask</h1>\n",
    "Extract data from 12 monthly files, then process selected dataset for target lat/lon.  Each file is ~2gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "csvpath=\"output/era5/\";outfile=\"\";yr=2018\n",
    "sitelon = 40.02 #example for Boulder, CO\n",
    "sitelat = -105.27 #example for Boulder, CO\n",
    "\n",
    "#Adj target lon to be on same scale as data\n",
    "sitelon=sitelon%360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amazing-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tricks to get around OS file cacheing so we can see actual read data performance...\n",
    "#These are all pointing to the same files.\n",
    "#e5path=\"/work/noaa/co2/kaushik/PVPRM/ERA5_PVPRM\"#orion\n",
    "e5path1='/home/ccg/mund/tmp/lns/e1/'\n",
    "e5path2='/home/ccg/mund/tmp/lns/e2/'\n",
    "e5path3='/home/ccg/mund/tmp/lns/e3/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-seating",
   "metadata": {},
   "source": [
    "<h3>Possible approaches</h3>\n",
    "<ul>\n",
    "<li>Loop through each monthly file, exctract data and write into intermediate data structure\n",
    "<li>Use xarray's open_mfdataset to combine files into 1 logical structure (41GB!), extract data and process.  This actually uses dask behind the scenes and runs in multi-threaded mode, so it's memory effecient and fairly fast    \n",
    "<li>Use xarray's open_mfdataset in parallel processing mode\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-might",
   "metadata": {},
   "source": [
    "<h4>Looping</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove this line to run... ~5-6 min\n",
    "%%time\n",
    "#Traditional looping method: \n",
    "outfile=\"looping_output.csv\"\n",
    "files=glob.glob(e5path1 + 'era5_daily_pvprm_%s*' %(yr))\n",
    "n=0;frames=[]\n",
    "for f in files:\n",
    "    t=xr.open_dataset(f)\n",
    "    tloc = t.sel(longitude=sitelon, latitude=sitelat, method ='nearest')\n",
    "    frames.append(tloc)\n",
    "looploc=xr.combine_by_coords(frames,combine_attrs='drop')\n",
    "looploc\n",
    "\n",
    "#CPU times: user 636 ms, sys: 1.4 s, total: 2.03 s\n",
    "#Wall time: 5min 13s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-wiring",
   "metadata": {},
   "source": [
    "<h4>Multi-threaded using Xarray open_mfdataset</h4>This uses Dask underneath with a multi-threaded cluster by default.  It is memory efficient, a cleaner algorithm and a little bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove this line to run... ~4 min\n",
    "%%time\n",
    "outfile=\"mt_output.csv\"\n",
    "dsm = xr.open_mfdataset(e5path2 + 'era5_daily_pvprm_%s*' %(yr))\n",
    "\n",
    "# subset location, put into dataframe \n",
    "dsmloc = dsm.sel(longitude=sitelon, latitude=sitelat, method ='nearest').compute()\n",
    "#dsmloc\n",
    "\n",
    "#CPU times: user 566 ms, sys: 1.44 s, total: 2 s\n",
    "#Wall time: 4min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-deviation",
   "metadata": {},
   "source": [
    "<h4>Multi-process using Xarray open_mfdataset</h4>\n",
    "Use dask explicitly to create a multi-processing cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "above-revision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://nimbus2:8750</li>\n",
       "  <li><b>Dashboard: </b><a href='http://nimbus2:8787/status' target='_blank'>http://nimbus2:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>66.82 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://140.172.192.149:8750' processes=8 threads=16, memory=66.82 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress, SSHCluster\n",
    "#client = Client()#Default mp cluster\n",
    "client=Client(address='nimbus2:8750')#ssh nimbi cluster, started from command line\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "injured-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - WARNING - Couldn't gather 4 keys, rescheduling {'open_dataset-8f6aeacf-a222-4c87-82db-1d9ce0c3a147': ('tcp://[::1]:41129',), 'open_dataset-8677c7f4-ef05-4815-8439-afbcc777acfe': ('tcp://[::1]:34615',), 'getattr-41539605-39b5-4540-9745-950d6aca57b2': ('tcp://[::1]:34615',), 'getattr-0b9da0db-0505-44b6-a082-854d1ed04924': ('tcp://[::1]:41129',)}\n",
      "distributed.client - WARNING - Couldn't gather 8 keys, rescheduling {\"('getitem-bfe6560697f950b12e7f705fec85ba7a', 5)\": ('tcp://[::1]:41129',), \"('getitem-339a267df8abcaf1960f1715bf4719f6', 7)\": ('tcp://[::1]:34615',), \"('getitem-8bc2a292356e7ece96016fbe8c277694', 4)\": ('tcp://[::1]:41129',), \"('getitem-81588c7caf5d6e66594fc0567d85d0f7', 0)\": ('tcp://[::1]:41129',), \"('getitem-81588c7caf5d6e66594fc0567d85d0f7', 7)\": ('tcp://[::1]:41129',), \"('getitem-bfe6560697f950b12e7f705fec85ba7a', 10)\": ('tcp://[::1]:34615',), \"('getitem-339a267df8abcaf1960f1715bf4719f6', 0)\": ('tcp://[::1]:34615',), \"('getitem-eb25ac9ecc3c16d577b9c47c61579b3e', 2)\": ('tcp://[::1]:34615',)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 847 ms, sys: 71.2 ms, total: 918 ms\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#CPU times: user 11.9 s, sys: 1.22 s, total: 13.1 s\n",
    "#Wall time: 2min 56s\n",
    "outfile=\"mp_output.csv\"\n",
    "dsm = xr.open_mfdataset(e5path3 + 'era5_daily_pvprm_%s*' %(yr),parallel=True,chunks={'latitude': 10, 'longitude': 10})\n",
    "dsmloc = dsm.sel(longitude=sitelon, latitude=sitelat, method ='nearest').compute()\n",
    "#dsmloc\n",
    "\n",
    "#CPU times: user 854 ms, sys: 0 ns, total: 854 ms\n",
    "#Wall time: 27.4 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DSM size in GB:\",dsm.nbytes / 1e9)\n",
    "print(\"DSMloc size in GB:\",dsmloc.nbytes / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-queen",
   "metadata": {},
   "source": [
    "<h3>Process selected data into output</h3>\n",
    "Filter data using Dask, then use Numpy, Pandas & Xarray to process.  This is fast because we're now working on a relatively small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "joined-poker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 8.93 ms, total: 137 ms\n",
      "Wall time: 642 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# do some math/edit the arrays \n",
    "\n",
    "dfmloc=dsmloc.to_dataframe()\n",
    "\n",
    "# avg soil data, convert stl1+stl2 to avg and append\n",
    "soilt=(dfmloc.stl1+dfmloc.stl2)/2.\n",
    "dfmloc['Ts.ERA5']=soilt\n",
    "\n",
    "# drop stl1, stl2, lat, lon\n",
    "dfmloc2=dfmloc.drop(['ssrd','stl1','stl2','latitude','longitude'],axis=1)\n",
    "#del dfmloc\n",
    "\n",
    "# rename t2m,par into new dataframe\n",
    "dfmloc3=dfmloc2.rename(columns={\"t2m\":\"Ta.ERA5\",\"par\":\"PAR.ERA5\"})\n",
    "#del dfmloc2\n",
    "\n",
    "# convert Ta and Ts to Celsius\n",
    "dfmloc3['Ta.ERA5']=dfmloc3['Ta.ERA5']-273.15\n",
    "dfmloc3['Ts.ERA5']=dfmloc3['Ts.ERA5']-273.15\n",
    "# new time index going up to 23:30 on 12/31 -- era5 data ends at 23:00\n",
    "t_index=pd.date_range(start='%s-01-01 00:00:00' %(yr), end='%s-12-31 23:30:00' %(yr), freq='30T')\n",
    "\n",
    "#resample on 30min timestep, interpolate (default linear?), reindex to t_index to go up to 23:30, /\n",
    "#forward fill last value, reset index so that time is one  of the columns\n",
    "dfmloc_rs=dfmloc3.resample('30T').interpolate().reindex(t_index).ffill().reset_index()\n",
    "\n",
    "# save to dataframe, rename index column to time\n",
    "dfm=dfmloc_rs.rename(columns={\"index\":\"time\"})\n",
    "#del dfmloc_rs\n",
    "\n",
    "#Output to csv\n",
    "dfm.to_csv(csvpath+outfile,index=False)\n",
    "#del dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-coalition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
